<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="支持向量机（SVM）算法-补充说明"><meta name="keywords" content="python,SVM,补充说明"><meta name="author" content="Yyb,undefined"><meta name="copyright" content="Yyb"><title>支持向量机（SVM）算法-补充说明【Yyb的花园】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!-- link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!-- link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!-- script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"VN5QYUXW8S","apiKey":"7bb2817029d8aaa580ce39e2aef50ce7","indexName":"search","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  gitment: {},
  valine: {"appId":"S3SM93qxXfn8olHkcUQnJuIp-gzGzoHsz","appKey":"dJ07LxI5XAsyjJ3DB7zmCUL3","placeholder":"走过路过不要错过,买不买的瞧一瞧啊!","pageSize":10},
}</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Yyb的花园" type="application/atom+xml">
</head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E"><span class="toc-number">1.</span> <span class="toc-text">支持向量机（SVM）算法-补充说明</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%8F"><span class="toc-number">1.1.</span> <span class="toc-text">序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E6%8A%80%E5%B7%A7"><span class="toc-number">1.2.</span> <span class="toc-text">核技巧</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%90%86%E8%A7%A3SVM"><span class="toc-number">1.3.</span> <span class="toc-text">理解SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE-%E6%95%B0%E6%8D%AE%E7%BC%A9%E6%94%BE"><span class="toc-number">1.4.</span> <span class="toc-text">预处理数据-数据缩放</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-number">1.5.</span> <span class="toc-text">参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">小结</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Yyb</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://mp.csdn.net/console/article?spm=1010.2135.3001.5416" target="_blank">CSDN<i class="icon-dot bg-color5"></i></a><a class="links-button button-hover" href="1994yybsr@sina.com" target="_blank">E-Mail<i class="icon-dot bg-color4"></i></a><a class="links-button button-hover" href="https://github.com/yb705" target="_blank">GitHub<i class="icon-dot bg-color4"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">19</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">20</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">13</span></a></div><div class="friend-link"><a class="friend-link-text" href="https://github.com/yb705" target="_blank">不怎么用的github</a><a class="friend-link-text" href="https://i.csdn.net/#/user-center/profile?spm=1010.2135.3001.5111" target="_blank">定期更新的CSDN</a><a class="friend-link-text" href="1994yybsr@sina.com" target="_blank">只用来接收消息的邮箱</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">Yyb的花园</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">支持向量机（SVM）算法-补充说明</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2021-06-15 | 更新于 2021-06-15</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">监督学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E6%A0%B8%E5%90%91%E9%87%8F%E6%9C%BA/">核向量机</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/python/">python</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/SVM/">SVM</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/">补充说明</a></div></div></div><div class="main-content"><h1 id="支持向量机（SVM）算法-补充说明"><a href="#支持向量机（SVM）算法-补充说明" class="headerlink" title="支持向量机（SVM）算法-补充说明"></a>支持向量机（SVM）算法-补充说明</h1><h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>之前我有写过一篇关于svm的使用流程和基本概念讲解——<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115350097">支持向量机（SVM）算法之分类实操</a>。不过最近又接触了一些关于svm的基础概念和预处理数据的使用，所以在这里做一下简单地补充。在接触本篇文章之前，建议先去看完<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115350097">支持向量机（SVM）算法之分类实操</a>，一些我之前讲过的东西，这里就不在赘述了。</p>
<h2 id="核技巧"><a href="#核技巧" class="headerlink" title="核技巧"></a>核技巧</h2><p>首先需要声明的一点是，向数据表示中添加非线性特征，可以让线性模型变得更强大。但是，通常来说我们并不知道要添加哪些特征，而添加许多特征（比如100维特征空间所有可能的交互项）的计算开销可能会很大。幸运的是，有一种巧妙的数学技巧，让我们可以在更高维空间中学习分类器，而不用实际计算可能非常大的新的数据表示。这种技巧叫做<strong>核技巧</strong>，它的原理是直接计算特征表示中数据点之间的距离（更准确地说是内积），而不用实际对扩展进行计算。</p>
<p>对于支持向量机，将数据映射到更高维空间中有两种常用的办法，也就是在<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115350097">支持向量机（SVM）算法之分类实操</a>中提到过的核参数：一种是<strong>多项式核</strong>，在一定阶数内计算原始特征所有可能的多项式（比如feature1＊<em>2+feature2＊</em>2）；另一种是<strong>径向基函数（RBF）核</strong>，也叫高斯核。高斯核有点难以解释，因为它对应无限维的特征空间。一种对高斯核的解释是它考虑所有阶数的所有可能的多项式，但阶数越高，特征的重要性越小。</p>
<p>当然在实际中，核svm背后的数学细节并不是很重要。</p>
<span id="more"></span>

<h2 id="理解SVM"><a href="#理解SVM" class="headerlink" title="理解SVM"></a>理解SVM</h2><p>与线性模型相比，核支持向量机（通常简称为SVM）是可以推广到更复杂模型的扩展，这些模型无法被输入线性函数进行定义，譬如下面的数据：<br><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/2021051213473747.png" alt="在这里插入图片描述"><br><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512140025880.png" alt="在这里插入图片描述"><br>如上图所示，在训练过程中，SVM学习每个数据点对于表示两个类别之间的决策边界的重要性。通常只有一部分训练数据点对于定义决策边界来说很重要：位于类别之间边界上的那些点。这些点叫做<strong>支持向量</strong>，支持向量机正是由此得名。</p>
<p>想要对新样本点进行预测，需要测量它与每个支持向量之间的距离。分类决策是基于它与支持向量之间的距离以及在训练过程中学到的支持向量重要性来做出的。</p>
<p>数据点之间的距离有<strong>高斯核</strong>给出:</p>
<blockquote>
<p><strong>k(x1,x2)=exp(-y||x1-x2||^2)</strong><br>x1,x2——数据点；||x1-x2||——表示欧式距离；y（gamma）——控制高斯核宽度的参数</p>
</blockquote>
<h2 id="预处理数据-数据缩放"><a href="#预处理数据-数据缩放" class="headerlink" title="预处理数据-数据缩放"></a>预处理数据-数据缩放</h2><p>首先我们先对一个数据集<a target="_blank" rel="noopener" href="https://www.kaggle.com/andrewmvd/fetal-health-classification">胎儿健康分类</a>进行简单的建模，这个数据之前有讲到过，在这里就不在赘述了，具体代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> winreg</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment">###################</span></span><br><span class="line">real_address = winreg.OpenKey(winreg.HKEY_CURRENT_USER,<span class="string">r&#x27;Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders&#x27;</span>,)</span><br><span class="line">file_address=winreg.QueryValueEx(real_address, <span class="string">&quot;Desktop&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">file_address+=<span class="string">&#x27;\\&#x27;</span></span><br><span class="line">file_origin=file_address+<span class="string">&quot;\\源数据-分析\\fetal_health.csv&quot;</span></span><br><span class="line">health=pd.read_csv(file_origin)</span><br><span class="line"><span class="comment">#设立桌面绝对路径，读取源数据文件，这样将数据直接下载到桌面上就可以了，省得还要去找</span></span><br><span class="line"><span class="comment">###################</span></span><br><span class="line">train=health.drop([<span class="string">&quot;fetal_health&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">X_train,X_test,y_train,y_test=train_test_split(train,health[<span class="string">&quot;fetal_health&quot;</span>],random_state=<span class="number">1</span>)</span><br><span class="line"><span class="comment">###考虑到接下来可能需要进行其他的操作，所以定了一个随机种子，保证接下来的train和test是同一组数</span></span><br><span class="line">svm_Notlinear=svm.SVC(C=<span class="number">1</span>,kernel=<span class="string">&quot;rbf&quot;</span>,decision_function_shape=<span class="string">&quot;ovr&quot;</span>)</span><br><span class="line">svm_Notlinear.fit(X_train,y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM训练模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_train,svm_Notlinear.predict(X_train))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM待测模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_test,svm_Notlinear.predict(X_test))))</span><br></pre></td></tr></table></figure>

<p>结果如下所示：<br><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512143227271.png" alt="在这里插入图片描述"><br>虽然SVM的表现通常都很好，但它对参数的设定和数据的缩放非常敏感。特别的，它要求所有特征有相似的变化范围。解决这个问题的一种方法就是对每个特征进行缩放，使其大致都位于一个范围。核SVM常用的缩放方法就是将所有特征缩放到0到1之间，实际上MinMaxScaler预处理方法就可以做到这一点，但是为了大家更好地理解，这里我们手动缩放一下，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">range_train=(X_train-X_train.<span class="built_in">min</span>()).<span class="built_in">max</span>(axis=<span class="number">0</span>)<span class="comment">###计算各个特征值的最大距离</span></span><br><span class="line">scaled_train=(X_train-X_train.<span class="built_in">min</span>(axis=<span class="number">0</span>))/range_train<span class="comment">###看看各个特征维度里面的个体数值距离与最大距离的比，这样所有的特征个体数据都在0到1之间</span></span><br><span class="line">scaled_test=(X_test-X_train.<span class="built_in">min</span>(axis=<span class="number">0</span>))/range_train<span class="comment">###测试集进行同样的缩放，注意是利用训练集缩放测试集</span></span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line">svm_Notlinear=svm.SVC(C=<span class="number">1</span>,kernel=<span class="string">&quot;rbf&quot;</span>,decision_function_shape=<span class="string">&quot;ovr&quot;</span>)</span><br><span class="line">svm_Notlinear.fit(scaled_train,y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM训练模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_train,svm_Notlinear.predict(scaled_train))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SVM待测模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_test,svm_Notlinear.predict(scaled_test))))</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512143756876.png" alt="在这里插入图片描述"><br>从上面的结果可以看出，模型精度较之前有了提高。<strong>在实际应用过程中，我们会遇到各种各样的数据，如果我们不能保证数据特征的统一性，那么数据缩放就会取到非常大的作用！</strong></p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>之前我们在<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115350097">支持向量机（SVM）算法之分类实操</a>中已经讲过各种核函数的适用范围，这里就不在多说了，如下图所示：<br><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512160537252.png" alt="在这里插入图片描述"><br>下面说一下另外两个参数C和gamma。</p>
<p>gamma是核技巧中给出的公式中的参数，用于控制高斯核的宽度。它决定了点与点之间“靠近”是指多大的距离。C是正则化参数，与线性模型中用到的类似。它限制每个点的重要性。</p>
<p>gamma较小，说明高斯核的半径较大，许多点都被看作比较接近。小的gamma值表示决策边界变化很慢，生成的是复杂度较低的模型，而大的gamma值则会生成更为复杂的模型。</p>
<p>至于参数C，与线性模型相同，如果C值很小，说迷你跟模型非常受限，每个数据点的影响范围都有限。</p>
<p>一般情况下，SVM中默认C=1，gamma=1/n_features。</p>
<p>接下来，我们来分别调节这两个参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">result_gamma=pd.DataFrame(columns=[<span class="string">&quot;gamma&quot;</span>,<span class="string">&quot;SVM训练模型评分&quot;</span>,<span class="string">&quot;SVM待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">100</span>):</span><br><span class="line">    svm_Notlinear=svm.SVC(C=<span class="number">1</span>,gamma=i/<span class="number">10</span>,kernel=<span class="string">&quot;rbf&quot;</span>,decision_function_shape=<span class="string">&quot;ovr&quot;</span>)</span><br><span class="line">    svm_Notlinear.fit(scaled_train,y_train)</span><br><span class="line">    result_gamma=result_gamma.append([&#123;<span class="string">&quot;gamma&quot;</span>:i/<span class="number">10</span>,<span class="string">&quot;SVM训练模型评分&quot;</span>:accuracy_score(y_train,svm_Notlinear.predict(scaled_train)),<span class="string">&quot;SVM待测模型评分&quot;</span>:accuracy_score(y_test,svm_Notlinear.predict(scaled_test))&#125;])</span><br><span class="line">result_gamma[result_gamma[<span class="string">&quot;SVM待测模型评分&quot;</span>]==result_gamma[<span class="string">&quot;SVM待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512161459449.png" alt="在这里插入图片描述"><br>接下来，在保证gamma值不变的情况下，调节C参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">result_C=pd.DataFrame(columns=[<span class="string">&quot;C&quot;</span>,<span class="string">&quot;SVM训练模型评分&quot;</span>,<span class="string">&quot;SVM待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">500</span>,<span class="number">10</span>):</span><br><span class="line">    svm_Notlinear=svm.SVC(C=i,gamma=<span class="number">3.1</span>,kernel=<span class="string">&quot;rbf&quot;</span>,decision_function_shape=<span class="string">&quot;ovr&quot;</span>)</span><br><span class="line">    svm_Notlinear.fit(scaled_train,y_train)</span><br><span class="line">    result_C=result_C.append([&#123;<span class="string">&quot;C&quot;</span>:i,<span class="string">&quot;SVM训练模型评分&quot;</span>:accuracy_score(y_train,svm_Notlinear.predict(scaled_train)),<span class="string">&quot;SVM待测模型评分&quot;</span>:accuracy_score(y_test,svm_Notlinear.predict(scaled_test))&#125;])</span><br><span class="line">result_C[result_C[<span class="string">&quot;SVM待测模型评分&quot;</span>]==result_C[<span class="string">&quot;SVM待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/20210512162044745.png" alt="在这里插入图片描述"><br>至此，这个SVM的模型就简单地调节好了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>核支持向量机是非常强大的模型，在各种数据集上的表现都很好。SVM允许决策边界很复杂，即使数据只有几个特征。它在低维数据和高维数据（即很少特征和很多特征）上的表现都很好，但对样本个数的缩放表现不好。在有多达10000个样本的数据上运行SVM可能表现良好，但如果数据量达到1000000甚至更大，在运行时间和内存使用方面可能会面临挑战。</p>
<p>SVM的另一个缺点是，预处理数据和调参都需要非常小心。这也是为什么如今很多应用中用的都是基于树的模型，比如随机森林或梯度提升（需要很少的预处理，甚至不需要预处理）。此外，SVM模型很难检查，可能很难理解为什么会这么预测，而且也很难将模型向非专家进行解释。</p>
<p>不过SVM仍然是值得尝试的，特别是所有特征的测量单位相似（比如都是像素密度），而且范围也差不多时。</p>
<p>核SVM的重要参数是正则化参数C，核的选择以及与核相关的参数。虽然我们主要讲的是RBF核，但scikit-learn中还有其它选择。RBF核只有一个参数gamma，它是高斯核宽度的倒数。gamma和C控制的都是模型复杂度，较大的值都对应更为复杂的模型。因此，这两个参数的设定通常是强烈相关的，应该同时调节。</p>
<p>有很多地方做的不是很好，欢迎网友来提出建议，也希望可以遇到些朋友来一起交流讨论。</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Yyb</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://yb705.github.io/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/">https://yb705.github.io/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yb705.github.io">Yyb的花园</a>！</span></div></div><div class="post-copyright valine" id="comments-container"><script src="//unpkg.com/valine@1.4.14/dist/Valine.min.js"></script><script>let arr = location.href.split('/#more')[0].split('/');
let title = arr[arr.length - 1];
if (title === '') {
    title = arr[arr.length - 2];
}
var flag = false;
var gitFun = function () {
    try {
        var valineObj = window.GLOBAL_CONFIG.valine;
        new Valine({
            el: "#comments-container",
            ...valineObj
        });
        flag = true;
    } catch (e) {
        flag = false;
    }
}
var setIn = setInterval(() => {
    if (!flag) {
        gitFun();
    } else {
        clearInterval(setIn);
    }
}, 200);</script></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2021/06/15/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%89%E7%AE%97%E6%B3%95-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/"><i class="fas fa-angle-left">&nbsp;</i><span>支持向量机（SVM）算法-实际应用</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2021/06/15/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%89%E7%AE%97%E6%B3%95/"><span>神经网络（深度学习）算法</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2021 By Yyb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>