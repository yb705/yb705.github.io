<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="决策树集成-随机森林随机森林"><meta name="keywords" content="python,梯度提升回归树"><meta name="author" content="Yyb,undefined"><meta name="copyright" content="Yyb"><title>决策树集成-随机森林随机森林【Yyb的花园】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!-- link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!-- link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!-- script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"VN5QYUXW8S","apiKey":"7bb2817029d8aaa580ce39e2aef50ce7","indexName":"search","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  gitment: {},
  valine: {"appId":"S3SM93qxXfn8olHkcUQnJuIp-gzGzoHsz","appKey":"dJ07LxI5XAsyjJ3DB7zmCUL3","placeholder":"走过路过不要错过,买不买的瞧一瞧啊!","pageSize":10},
}</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Yyb的花园" type="application/atom+xml">
</head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91"><span class="toc-number">1.</span> <span class="toc-text">决策树集成-梯度提升回归树</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="toc-number">1.1.</span> <span class="toc-text">基础概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E6%83%B3%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.</span> <span class="toc-text">思想简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E6%93%8D%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.3.</span> <span class="toc-text">实操建模</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0"><span class="toc-number">1.4.</span> <span class="toc-text">模型参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">1.5.</span> <span class="toc-text">分析特征重要性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.6.</span> <span class="toc-text">优缺点</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Yyb</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://mp.csdn.net/console/article?spm=1010.2135.3001.5416" target="_blank">CSDN<i class="icon-dot bg-color7"></i></a><a class="links-button button-hover" href="1994yybsr@sina.com" target="_blank">E-Mail<i class="icon-dot bg-color2"></i></a><a class="links-button button-hover" href="https://github.com/yb705" target="_blank">GitHub<i class="icon-dot bg-color5"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">19</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">20</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">13</span></a></div><div class="friend-link"><a class="friend-link-text" href="https://github.com/yb705" target="_blank">不怎么用的github</a><a class="friend-link-text" href="https://i.csdn.net/#/user-center/profile?spm=1010.2135.3001.5111" target="_blank">定期更新的CSDN</a><a class="friend-link-text" href="1994yybsr@sina.com" target="_blank">只用来接收消息的邮箱</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">Yyb的花园</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">决策树集成-随机森林随机森林</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2021-06-15 | 更新于 2021-06-15</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">监督学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90/">决策树集成</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/python/">python</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/">梯度提升回归树</a></div></div></div><div class="main-content"><h1 id="决策树集成-梯度提升回归树"><a href="#决策树集成-梯度提升回归树" class="headerlink" title="决策树集成-梯度提升回归树"></a>决策树集成-梯度提升回归树</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p><strong>集成</strong></p>
<p>集成是合并多个机器学习模型来构建更强大模型的方法。在机器学习算法中有许多模型属于这一类，但已证明有两种集成模型对大量分类和回归的数据集都是有效的，二者都以决策树为基础，分别是<strong>随机森林（random forest）</strong>和<strong>梯度提升决策树（gradiet boosted decision tree）</strong>。</p>
<p>之前已经讲解过了随机森林(<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116231286">决策树集成-随机森林之分类实操</a>),这次讲解<strong>梯度提升决策树</strong>。在了解梯度提升决策树之前,建议先去看一下我的另外两篇讲解决策树的文章<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115696198">决策树算法之讲解实操（上）</a>和<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115939923">决策树算法之讲解实操（下）</a>，重复的东西，我这里就不在赘述了。</p>
<h2 id="思想简介"><a href="#思想简介" class="headerlink" title="思想简介"></a>思想简介</h2><p>在之前的一篇文章<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115696198">决策树算法之讲解实操（上）</a>中我们提到过，决策树的一个主要缺点在于经常对训练数据过拟合。那么除了随机森林之外,梯度提升回归树就是解决这个问题的另一种方法。</p>
<p>梯度提升回归树是通过合并多个决策树来构建一个更为强大的模型。虽然名字中含有”回归”，但是这个模型既可以用于回归也可以用于分类。与随机森林的方法不同,<strong>梯度提升采用连续的方式构造树,每颗树都试图纠正前一棵树的错误</strong>.默认情况下,梯度提升回归树中没有随机化,而是用到了强预剪枝。<strong>梯度提升树通常使用深度很小(1到5之间)的树</strong>,这样模型占用的内存更少,预测速度也更快.</p>
<p><strong>梯度提升树背后的主要思想是合并许多简单的模型</strong>(在这个语境中叫做弱学习器),比如深度较小的树.每棵树只能对部分数据作出好的预测,因此,添加的树越来越多,可以不断迭代,提高性能.</p>
<p>梯度提升树经常是机器学习竞赛的优胜者,并广泛应用于业界.与随机森林相比,它通常对参数的设置更为敏感,但如果参数设置正确的话,模型精度会更高.</p>
<span id="more"></span>


<h2 id="实操建模"><a href="#实操建模" class="headerlink" title="实操建模"></a>实操建模</h2><p>数据是一份<a target="_blank" rel="noopener" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009">红酒质量分类</a>的数据集，通过各个维度来判断红酒质量，之前在<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115696198">决策树算法之讲解实操（上）</a>中已经讲解使用过了，这里就不多在赘述了，我们直接建模，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> winreg</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier<span class="comment">#梯度提升回归树</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment">###################</span></span><br><span class="line">real_address = winreg.OpenKey(winreg.HKEY_CURRENT_USER,<span class="string">r&#x27;Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders&#x27;</span>,)</span><br><span class="line">file_address=winreg.QueryValueEx(real_address, <span class="string">&quot;Desktop&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">file_address+=<span class="string">&#x27;\\&#x27;</span></span><br><span class="line">file_origin=file_address+<span class="string">&quot;\\源数据-分析\\winequality-red.csv&quot;</span><span class="comment">###https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009</span></span><br><span class="line">red_wine=pd.read_csv(file_origin)</span><br><span class="line"><span class="comment">#设立桌面绝对路径，读取源数据文件，这样将数据直接下载到桌面上就可以了，省得还要去找</span></span><br><span class="line"><span class="comment">###################</span></span><br><span class="line">train=red_wine.drop([<span class="string">&quot;quality&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">X_train,X_test,y_train,y_test=train_test_split(train,red_wine[<span class="string">&quot;quality&quot;</span>],random_state=<span class="number">1</span>)</span><br><span class="line"><span class="comment">###考虑到接下来可能需要进行其他的操作，所以定了一个随机种子，保证接下来的train和test是同一组数</span></span><br><span class="line">gbcf=GradientBoostingClassifier(random_state=<span class="number">1</span>)</span><br><span class="line">gbcf.fit(X_train,y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;梯度提升回归树训练模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_train,gbcf.predict(X_train))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;梯度提升回归树待测模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_test,gbcf.predict(X_test))))</span><br></pre></td></tr></table></figure>

<p>结果如下所示：<br><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210508121801300.png" alt="在这里插入图片描述"></p>
<p>下面是之前的文章中单棵决策树建立的模型结果：<br><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210428134820111.jpg" alt="在这里插入图片描述"><br>二者相比可以看出，梯度提升树的模型精度要比单棵树的要好一点，过拟合现象也比之前要减轻很多。<br>接下来我们了解一下梯度提升树的主要模型参数。</p>
<h2 id="模型参数"><a href="#模型参数" class="headerlink" title="模型参数"></a>模型参数</h2><p>在梯度提升回归树中，我们主要会用到三个模型参数n_estimators（树的个数），max_depth（树的深度）,learning_rate（学习率）,至于其它的参数，一般情况下直接默认就好。</p>
<p><strong>max_depth</strong>：用于降低每棵树的复杂度.一般来说,梯度提升模型的max_depth通常设置得很小,一般不超过5.<br>接下来我们来调节这个参数，提高模型精度，代码及结果如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">result_1=pd.DataFrame(columns=[<span class="string">&quot;决策树深度(max_depth)&quot;</span>,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">5</span>):</span><br><span class="line">    gbcf=GradientBoostingClassifier(max_depth=i,random_state=<span class="number">1</span>)</span><br><span class="line">    gbcf.fit(X_train,y_train)</span><br><span class="line">    result_1=result_1.append([&#123;<span class="string">&quot;决策树深度(max_depth)&quot;</span>:i,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>:accuracy_score(y_test,gbcf.predict(X_test))&#125;])</span><br><span class="line">result_1[result_1[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>]==result_1[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210508122322592.jpg" alt="在这里插入图片描述"></p>
<p>可以看到当我们设定参数max_depth为4的时候，模型精度可以达到66.5%左右，较之前的结果提高了一些。</p>
<p>梯度提升树模型的另外两个主要参数包括<strong>树的数量n_estimators</strong>和<strong>学习率learn_rate</strong>,后者<strong>用于控制每棵树对前一棵树的错误纠正程度</strong>.这两个参数高度相关,因为learning_rate越低,就需要更多的树来构建具有相似复杂度的模型.随机森林的n_estimators值总是越大越好,但是梯度提升不同,增大n_estimators会导致模型更加复杂,进而可能导致过拟合.<strong>通常的做法是根据时间和内存的预算选择合适的n_estimators,然后对不同的learning_rate进行遍历.</strong></p>
<p>这两个参数的调节代码及结果如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">result_2=pd.DataFrame(columns=[<span class="string">&quot;集成树的个数(n_estimators)&quot;</span>,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">500</span>,<span class="number">10</span>):</span><br><span class="line">    gbcf=GradientBoostingClassifier(max_depth=<span class="number">4</span>,n_estimators=i,random_state=<span class="number">1</span>)</span><br><span class="line">    gbcf.fit(X_train,y_train)</span><br><span class="line">    result_2=result_2.append([&#123;<span class="string">&quot;集成树的个数(n_estimators)&quot;</span>:i,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>:accuracy_score(y_test,gbcf.predict(X_test))&#125;])</span><br><span class="line">result_2[result_2[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>]==result_2[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/2021050812303492.jpg" alt="在这里插入图片描述"><br>n_estimators的调节结果如上图所示,那么接下来我们在上面的参数基础上继续调节学习率:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">result_3=pd.DataFrame(columns=[<span class="string">&quot;学习率(learning_rate)&quot;</span>,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">10</span>):</span><br><span class="line">    m=i/<span class="number">10</span></span><br><span class="line">    gbcf=GradientBoostingClassifier(max_depth=<span class="number">4</span>,n_estimators=<span class="number">161</span>,learning_rate=m,random_state=<span class="number">1</span>)</span><br><span class="line">    gbcf.fit(X_train,y_train)</span><br><span class="line">    result_3=result_3.append([&#123;<span class="string">&quot;学习率(learning_rate)&quot;</span>:m,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>:accuracy_score(y_test,gbcf.predict(X_test))&#125;])</span><br><span class="line">result_3[result_3[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>]==result_3[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210508123248624.png" alt="在这里插入图片描述"><br>接下来,我们还可以对学习率的参数调节进行进一步的区间划分,代码及结果如下所示:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">result_4=pd.DataFrame(columns=[<span class="string">&quot;学习率(learning_rate)&quot;</span>,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">20</span>):</span><br><span class="line">    m=i/<span class="number">100</span></span><br><span class="line">    gbcf=GradientBoostingClassifier(max_depth=<span class="number">4</span>,n_estimators=<span class="number">161</span>,learning_rate=m,random_state=<span class="number">1</span>)</span><br><span class="line">    gbcf.fit(X_train,y_train)</span><br><span class="line">    result_4=result_4.append([&#123;<span class="string">&quot;学习率(learning_rate)&quot;</span>:m,<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>:accuracy_score(y_test,gbcf.predict(X_test))&#125;])</span><br><span class="line">result_4[result_4[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>]==result_4[<span class="string">&quot;梯度提升回归树待测模型评分&quot;</span>].<span class="built_in">max</span>()]</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210508123518243.png" alt="在这里插入图片描述"><br>至此,这个模型的参数就调节完毕了.<br>(ps:为了提高模型精度,参数是可以进行更近一步的调节,不过剩下的就需要朋友们自行探索了)</p>
<h2 id="分析特征重要性"><a href="#分析特征重要性" class="headerlink" title="分析特征重要性"></a>分析特征重要性</h2><p>与随机森林类似，梯度提升树也可以给出特征重要性,代码及结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">&quot;fivethirtyeight&quot;</span>)</span><br><span class="line">sns.set_style(&#123;<span class="string">&#x27;font.sans-serif&#x27;</span>:[<span class="string">&#x27;SimHei&#x27;</span>,<span class="string">&#x27;Arial&#x27;</span>]&#125;)</span><br><span class="line">%matplotlib inline</span><br><span class="line">gbcf=GradientBoostingClassifier(max_depth=<span class="number">4</span>,random_state=<span class="number">1</span>)<span class="comment">###梯度提升回归树</span></span><br><span class="line">forest=RandomForestClassifier(max_depth=<span class="number">4</span>,random_state=<span class="number">1</span>)<span class="comment">###随机森林分类器</span></span><br><span class="line">gbcf_prediction=gbcf.fit(X_train,y_train)</span><br><span class="line">forest_prediction=forest.fit(X_train,y_train)</span><br><span class="line">fig= plt.subplots(figsize=(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line">fig1 = plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;梯度提升回归树特征重要性&#x27;</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">plt.bar(train.columns,gbcf_prediction.feature_importances_,<span class="number">0.4</span>,color=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">fig2=plt.subplot(<span class="number">212</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;随机森林特征重要性&#x27;</span>,fontsize=<span class="number">20</span>)</span><br><span class="line">plt.bar(train.columns,forest_prediction.feature_importances_,<span class="number">0.4</span>,color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xticks(fontsize=<span class="number">13</span>)</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/20210508123904327.jpg" alt="在这里插入图片描述"></p>
<p>如上图所示，在保证树的深度参数（max_depth）相同的情况下，梯度提升树的特征重要性与随机森林的特征重要性有些相似,实际上在某些数据集中,梯度提升树可能会完全忽略某些特征.</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>梯度提升决策树是监督学习中最强大也是最常用的模型之一.其主要缺点是需要仔细调参,而且训练的时间可能会比较长.与其他基于树的模型类似,这一算法不需要对数据进行缩放就可以表现得很好,而且也<strong>适用于二元特征与连续特征同时存在的数据集</strong>.但它也通常不适用于高维稀疏数据.</p>
<p>由于梯度提升和随机森林两种方法在类似的数据上表现的都很好,因此一种常用的方法就是先尝试随机森林,它的鲁棒性很好.如果随机森林效果很好,但预测时间太长,或者机器学习模型精度小数点后第二位的提高也很重要,那么切换成梯度提升通常会有用.</p>
<p>有很多地方做的不是很好，欢迎网友来提出建议，也希望可以遇到些朋友来一起交流讨论。</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Yyb</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://yb705.github.io/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/">https://yb705.github.io/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%9B%9E%E5%BD%92%E6%A0%91/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yb705.github.io">Yyb的花园</a>！</span></div></div><div class="post-copyright valine" id="comments-container"><script src="//unpkg.com/valine@1.4.14/dist/Valine.min.js"></script><script>let arr = location.href.split('/#more')[0].split('/');
let title = arr[arr.length - 1];
if (title === '') {
    title = arr[arr.length - 2];
}
var flag = false;
var gitFun = function () {
    try {
        var valineObj = window.GLOBAL_CONFIG.valine;
        new Valine({
            el: "#comments-container",
            ...valineObj
        });
        flag = true;
    } catch (e) {
        flag = false;
    }
}
var setIn = setInterval(() => {
    if (!flag) {
        gitFun();
    } else {
        clearInterval(setIn);
    }
}, 200);</script></div></article><div id="pagination"><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2021/06/15/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E4%B8%8E%E7%BC%A9%E6%94%BE/"><span>数据预处理与缩放</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2021 By Yyb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>