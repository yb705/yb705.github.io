<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="分类器不确定度估计，监督学习算法小结"><meta name="keywords" content="python,算法小结"><meta name="author" content="Yyb,undefined"><meta name="copyright" content="Yyb"><title>分类器不确定度估计，监督学习算法小结【Yyb的花园】</title><link rel="stylesheet" href="/css/fan.css"><link rel="stylesheet" href="/css/thirdparty/jquery.mCustomScrollbar.min.css"><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4/dist/instantsearch-theme-algolia.min.css"><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.10.4"></script><!-- link(rel="dns-prefetch" href="https://cdn.jsdelivr.net")--><!-- link(rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.css")--><!-- script(src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.1.1/dist/instantsearch.min.js" defer)--><!-- script(src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML")--><script src="/js/mathjax/mathjax.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
});
</script><script>var isPassword = '' || false;
if (isPassword) {
    if (prompt('请输入文章密码') !== '') {
        alert('密码错误！');
        history.back();
    }
}</script><script>window.GLOBAL_CONFIG = {
  root: '/',
  algolia: {"appId":"VN5QYUXW8S","apiKey":"7bb2817029d8aaa580ce39e2aef50ce7","indexName":"search","hits":{"per_page":10},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容:${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  gitment: {},
  valine: {"appId":"S3SM93qxXfn8olHkcUQnJuIp-gzGzoHsz","appKey":"dJ07LxI5XAsyjJ3DB7zmCUL3","placeholder":"走过路过不要错过,买不买的瞧一瞧啊!","pageSize":10},
}</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Yyb的花园" type="application/atom+xml">
</head><body><canvas id="universe"></canvas><!--#body--><div id="sidebar"><div class="toggle-sidebar-info button-hover"><span data-toggle="文章目录">站点概览</span></div><div class="sidebar-toc"><div class="sidebar-toc-title">目录</div><div class="sidebar-toc-progress"><span class="progress-notice">您已阅读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc-progress-bar"></div></div><div class="sidebar-toc-content" id="sidebar-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%8F%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93"><span class="toc-number">1.</span> <span class="toc-text">分类器不确定度估计及监督学习算法小结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%8F"><span class="toc-number">1.1.</span> <span class="toc-text">序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="toc-number">1.2.</span> <span class="toc-text">数据来源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98"><span class="toc-number">1.3.</span> <span class="toc-text">数据挖掘</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.4.</span> <span class="toc-text">不确定度估计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93"><span class="toc-number">1.5.</span> <span class="toc-text">监督学习算法小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB"><span class="toc-number">1.6.</span> <span class="toc-text">学习分享</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info-avatar"><img class="author-info-avatar-img" src="/avatar.png"></div><div class="author-info-name">Yyb</div><div class="author-info-description"></div><div class="links-buttons"><a class="links-button button-hover" href="https://mp.csdn.net/console/article?spm=1010.2135.3001.5416" target="_blank">CSDN<i class="icon-dot bg-color5"></i></a><a class="links-button button-hover" href="1994yybsr@sina.com" target="_blank">E-Mail<i class="icon-dot bg-color8"></i></a><a class="links-button button-hover" href="https://github.com/yb705" target="_blank">GitHub<i class="icon-dot bg-color6"></i></a></div><div class="author-info-articles"><a class="author-info-articles-archives article-meta" href="/archives"><span class="pull-top">日志</span><span class="pull-bottom">19</span></a><a class="author-info-articles-tags article-meta" href="/tags"><span class="pull-top">标签</span><span class="pull-bottom">20</span></a><a class="author-info-articles-categories article-meta" href="/categories"><span class="pull-top">分类</span><span class="pull-bottom">13</span></a></div><div class="friend-link"><a class="friend-link-text" href="https://github.com/yb705" target="_blank">不怎么用的github</a><a class="friend-link-text" href="https://i.csdn.net/#/user-center/profile?spm=1010.2135.3001.5111" target="_blank">定期更新的CSDN</a><a class="friend-link-text" href="1994yybsr@sina.com" target="_blank">只用来接收消息的邮箱</a></div></div></div><div id="main-container"><header><div id="menu-outer"><i class="menu-list-icon fas fa-bars"></i><nav id="menu-inner"><a class="menu-item" href="/">首页</a><a class="menu-item" href="/tags">标签</a><a class="menu-item" href="/categories">分类</a><a class="menu-item" href="/archives">归档</a><a class="menu-item" href="/about">关于</a></nav><div class="right-info"><a class="search social-icon"><i class="fas fa-search"></i><span> 搜索</span></a><a class="title-name" href="/">Yyb的花园</a><span id="now-time"></span></div></div></header><div id="content-outer"><div id="content-inner"><article id="post"><div class="post-header"><div class="title">分类器不确定度估计，监督学习算法小结</div><div class="container"><time class="button-hover post-date"><i class="fas fa-calendar-alt article-icon" aria-hidden="true"></i> 发表于 2021-06-15 | 更新于 2021-06-15</time><!--time.button-hover.post-date #[i.fas.fa-calendar-alt.article-icon(aria-hidden="true")] #[=__('post.modified')] #[=date(page['updated'], config.date_format)]--><div class="button-hover categories"><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">监督学习</a><i class="fa fa-angle-right" style="margin: 0 8px;"></i><i class="fa fa-inbox article-icon" aria-hidden="true"></i><a class="link-a" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1/">分类器不确定度估计</a></div><div class="button-hover tags"><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/python/">python</a><span>&nbsp;|&nbsp;</span><i class="fa fa-tag article-icon" aria-hidden="true"></i><a class="link-a" href="/tags/%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/">算法小结</a></div></div></div><div class="main-content"><h1 id="分类器不确定度估计及监督学习算法小结"><a href="#分类器不确定度估计及监督学习算法小结" class="headerlink" title="分类器不确定度估计及监督学习算法小结"></a>分类器不确定度估计及监督学习算法小结</h1><h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>我们之前用到的所有机器学习的算法均来自于scikit—learn库，但是这个接口还有另一个用处，就是能够给出分类器预测结果的不确定性估计。有的时候，我们不仅要关心一个测试数据点究竟属于哪个类别，还要考虑这个预测的置信区间。譬如，在最近新冠疫情中出现的无症状感染，如果是假阳性预测，那么可能只会让患者接受额外的测试，但是如果是假阴性感染却有可能导致患者没有得到治疗。<strong>（</strong>机器学习的大部分算法均是建立在概率统计的基础上的，而概率等于99.9%却并不意味着事件一定会发生。<strong>）</strong></p>
<p>scikit—learn中有两个函数可用于获取分类器的不确定估计：<strong>decision_function和predict_proba</strong>。大多数分类器都至少有其中一个函数，很多分类器两个都有。接下来我们找一个数据集来构造一个<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116522395">梯度提升回归树</a>的分类器。（这个算法之前有讲过，不了解的小伙伴可以跳转到相应的文章去了解下。）</p>
<span id="more"></span>

<h2 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h2><p><a target="_blank" rel="noopener" href="https://www.kaggle.com/brsdincer/star-type-classification">星星分类：https://www.kaggle.com/brsdincer/star-type-classification</a></p>
<p><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602143118338.png" alt="在这里插入图片描述"><br>这个数据集并不大，只有240条数据记录，其中包括表面温度，颜色等特征，<strong>一共有6种星星（0-5）</strong>，而我们所需要做的就是通过这些特征值来对星星(Type)进行分类。</p>
<h2 id="数据挖掘"><a href="#数据挖掘" class="headerlink" title="数据挖掘"></a>数据挖掘</h2><p><strong>1.导入第三方库并读取文件</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> winreg</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier<span class="comment">#梯度提升回归树</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="comment">###################</span></span><br><span class="line">real_address = winreg.OpenKey(winreg.HKEY_CURRENT_USER,<span class="string">r&#x27;Software\Microsoft\Windows\CurrentVersion\Explorer\Shell Folders&#x27;</span>,)</span><br><span class="line">file_address=winreg.QueryValueEx(real_address, <span class="string">&quot;Desktop&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">file_address+=<span class="string">&#x27;\\&#x27;</span></span><br><span class="line">file_origin=file_address+<span class="string">&quot;\\源数据-分析\\Stars.csv&quot;</span><span class="comment">###https://www.kaggle.com/brsdincer/star-type-classification</span></span><br><span class="line">stars=pd.read_csv(file_origin)</span><br><span class="line"><span class="comment">#设立桌面绝对路径，读取源数据文件，这样将数据直接下载到桌面上就可以了，省得还要去找</span></span><br><span class="line"><span class="comment">###################</span></span><br></pre></td></tr></table></figure>

<p>老规矩，上来先依次导入建模需要的各个模块，并读取文件。</p>
<p><strong>2.清洗数据</strong></p>
<p>查找缺失值：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/2021060214350325.png" alt="在这里插入图片描述"><br>从上面的结果来看，数据中没有缺失值。但是数据中除了数字之外，还包括字符串，如果直接用字符串建模的话会报错，所以接下来我用数字依次替代字符串，代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> [<span class="string">&quot;Color&quot;</span>,<span class="string">&quot;Spectral_Class&quot;</span>]:</span><br><span class="line">    a=<span class="built_in">list</span>(<span class="built_in">set</span>(stars[i]))</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(a)):</span><br><span class="line">        stars.loc[stars[i]==a[m],i]=m</span><br></pre></td></tr></table></figure>

<p><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602143718488.png" alt="在这里插入图片描述"><br>好的，那么接下来我们开始构建模型。</p>
<p><strong>3.建模</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train=stars.drop([<span class="string">&quot;Type&quot;</span>],axis=<span class="number">1</span>)</span><br><span class="line">X_train,X_test,y_train,y_test=train_test_split(train,stars[<span class="string">&quot;Type&quot;</span>],random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>划分列索引为特征值和预测值，并将数据划分成训练集和测试集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gbcf=GradientBoostingClassifier(random_state=<span class="number">1</span>)</span><br><span class="line">gbcf.fit(X_train,y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;梯度提升回归树训练模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_train,gbcf.predict(X_train))))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;梯度提升回归树待测模型评分：&quot;</span>+<span class="built_in">str</span>(accuracy_score(y_test,gbcf.predict(X_test))))</span><br></pre></td></tr></table></figure>

<p>引入梯度提升决策树算法，并且让算法中的参数保持默认值就好。进行建模后，对测试集进行精度评分，得到的结果如下：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/2021060214393314.png" alt="在这里插入图片描述"></p>
<p>可以看到，该模型的精度为96%左右。当然，接下来我们还可以通过调参，来提高模型精度，不过本文主要讲解不确定度的问题，所以调参这部分就暂时先不讲了，有兴趣的朋友可以去<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116522395">决策树集成-梯度提升回归树之分类实操</a>看一下</p>
<h2 id="不确定度估计"><a href="#不确定度估计" class="headerlink" title="不确定度估计"></a>不确定度估计</h2><p><strong>decision_function</strong></p>
<p>对于多分类的情况，<strong>decision_function</strong>的形状为（n_samples,n_classes）,每一列对应每个类别的“确定度分数”，分数较高的类别可能性更大，得分较低的类别可能性较小，代码及结果如下所示：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602144903332.png" alt="在这里插入图片描述"><br>这里我们只看前5个数据点，可以看到每一个用中括号包括起来的一行就是一个数据点在6个分类中的得分，分数越高，属于该类别的概率就越高。譬如，第一行：“[-10.22462681, -10.21235435, -10.24571233, -10.00954012,7.89471131, -10.32103418]”中第五个数值最高，所以第一个数据点属于类别4的星星概率最高。</p>
<p>当然，我们还可以利用argmax找出每个数据点的最大元素，以及这些元素所对应的索引，从而利用这些分数再现预测结果，代码及结果如下所示：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602145721262.png" alt="在这里插入图片描述"><br>这一串数字就代表每个数据点所对应的类别，可以看到前五个数据分别属于类别4，1，2，3，4。</p>
<p><strong>predict_proba</strong></p>
<p>与decision_function不同，<strong>predict_proba</strong>的输出是每个类别的概率，通常比decision_function更容易理解。同时它的输出形状也是（n_samples,n_classes）。</p>
<p><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/2021060215150622.png" alt="在这里插入图片描述"><br>如上图所示，每行的第一个元素是第一个类别的估计概率，第二个元素是第二个类别的估计概率，依次类推。由于predict_proba的输出是一个概率，因此总是在0到1之间，元素之和始终为1。由于概率之和为1，因此只要有一个类别的概率超过50%，那么这个类别就是模型的预测结果。（ps：由于概率是浮点数，所以二分类问题中不太可能有两个0.5000，但是如果出现了这种情况，那么预测的结果就是随机的。）</p>
<p>同样地，我们可以通过计算predict_proba的argmax来再现预测结果，结果如下所示：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602152013254.png" alt="在这里插入图片描述"><br>一般情况下，如果你想要对比predict的结果与predict_proba或decision_function的结果，那么我们可以考虑用分类器的classes_属性来获取真实的属性名称：<br><img src="/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/20210602152202569.png" alt="在这里插入图片描述"><br>这里可以看出gbcf的6种分类类别的真实名称0，1，2，3，4，5。（说实话在这个数据集选取的并不好，因为是以数字来当作分类类别的，不太容易区分。）</p>
<h2 id="监督学习算法小结"><a href="#监督学习算法小结" class="headerlink" title="监督学习算法小结"></a>监督学习算法小结</h2><p>时间过得很快，三个多月前我开始接触机器学习，并且开始坚持一周学习一个算法，找其它数据练手，并且写下文章来记录。到目前为止，一些基础的监督学习算法已经全部完结了。接下来，我们来对这些算法做一个简单地总结，并附上链接，方便及时复习：</p>
<p><strong>最近邻</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/111628241">k邻近算法分类</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/112005984">k邻近算法回归</a>）<br>适用于小型数据集,是很好的基准模型,很容易解释。</p>
<p><strong>线性模型</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/112271333">最小二乘法</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/112931842">岭回归</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/112983192">lasso回归</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/112277248">LogisticRegression算法</a>）<br>非常可靠的首选算法,适用于非常大的数据集,也适用于高维数据。</p>
<p><strong>朴素贝叶斯</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115541911">朴素贝叶斯分类器</a>）<br>只适用于分类问题。比线性模型速度还快,适用于非常大的数据集和高维数据。精度通常要低于线性模型。</p>
<p><strong>决策树</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115696198">决策树算法之讲解实操（上）</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115939923">决策树算法之讲解实操（下）</a>）<br>速度很快,不需要数据缩放,可以进行可视化,很容易解释。</p>
<p><strong>随机森林</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116231286">决策树集成-随机森林之分类实操</a>）<br>几乎总是比单棵决策树的表现要好,鲁棒性很好,非常强大。不需要数据缩放。不适用于高维稀疏数据。</p>
<p><strong>梯度提升决策树</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116522395">决策树集成-梯度提升回归树之分类实操</a>）<br>精度通常比随机森林略高。与随机森林相比,训练速度更慢,但预测速度更快,需要的内存也更少。比随机森林需要更多的参数调节。</p>
<p><strong>支持向量机</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/115350097">支持向量机（SVM）</a>，<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/116704969">补充说明</a>）<br>对于特征含义相似的中等大小的数据集很强大。需要数据缩放,对参数敏感。</p>
<p><strong>神经网络</strong>（<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43580339/article/details/117256873">神经网络（深度学习）算法之分类实操</a>）<br>可以构建非常复杂的模型,特别是对于大型数据集而言。对数据缩放敏感,对参数选取敏感。大型网络需要很长的训练时间</p>
<p>我们之前有讨论了模型复杂度,然后讨论了泛化,或者说学习一个能够在前所未见的新数据上表现良好的模型。这就引出了<strong>欠拟合</strong>和<strong>过拟合</strong>的概念,前者是指一个模型无法获取数据中的所有变化,后者是指模型过分关注训练数据,但对新数据的泛化性能不好。</p>
<p>在我们讨论了一系列用于分类和回归的机器学习模型之后，就会发现对于许多算法而言,设置正确的参数对模型性能至关重要。有些算法还对输入数据的表示方式很敏感,特别是特征的缩放。因此,如果盲目地将一个算法应用于数据集,而不去理解模型所做的假设以及参数设定的含义,不太可能会得到精度高的模型。</p>
<p>通常我们在面对新数据集的时候，最好先从简单的模型开始，比如线性模型，朴素贝叶斯或最近临分类器，看看能得到什么效果。在对数据有了进一步的了解之后，我们再进一步考虑用于构建更复杂模型的算法，比如随机森林，梯度提升决策树，SVM或神经网络。</p>
<h2 id="学习分享"><a href="#学习分享" class="headerlink" title="学习分享"></a>学习分享</h2><p>其实在日常生活中，博主很喜欢逛知乎，当时决定要转行学习数据分析之前，也是到知乎，论坛上找了很多资料，然后看了很多人提问题，比如说“数据分析的发展前景怎么样？”，“学数据分析需要看什么书？”，“有没有大佬说一下课程推荐，或者是学习计划？”，甚至还有“学数据分析要不要买台好一点的电脑？”这样的问题。而截至到今天我已经学习了3个多月了，每周坚持更新一篇博文，然后等到我今天再去逛知乎，论坛的时候，发现当时在问类似问题的人，现在还在问这些问题，而并没有开始行动。虽然我并不知道那些人是不是营销号，但我希望他们是。希望看到这篇文章的人可以先做再说。</p>
<p>最后我有一句话送给打算努力或者正在努力的人，这句话也是我目前学习的动力之一，那就是：<br><strong>“心不妥协，行不受限，德智之高，莫若于知行合一。”</strong></p>
<p>与君共勉</p>
</div><div class="post-copyright"><div class="post-copyright-author"><span class="post-copyright-meta">本文作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Yyb</a></span></div><div class="post-copyright-type"><span class="post-copyright-meta">本文链接: </span><span class="post-copyright-info"><a href="https://yb705.github.io/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/">https://yb705.github.io/2021/06/15/%E5%88%86%E7%B1%BB%E5%99%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E5%BA%A6%E4%BC%B0%E8%AE%A1%EF%BC%8C%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/</a></span></div><div class="post-copyright-notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yb705.github.io">Yyb的花园</a>！</span></div></div><div class="post-copyright valine" id="comments-container"><script src="//unpkg.com/valine@1.4.14/dist/Valine.min.js"></script><script>let arr = location.href.split('/#more')[0].split('/');
let title = arr[arr.length - 1];
if (title === '') {
    title = arr[arr.length - 2];
}
var flag = false;
var gitFun = function () {
    try {
        var valineObj = window.GLOBAL_CONFIG.valine;
        new Valine({
            el: "#comments-container",
            ...valineObj
        });
        flag = true;
    } catch (e) {
        flag = false;
    }
}
var setIn = setInterval(() => {
    if (!flag) {
        gitFun();
    } else {
        clearInterval(setIn);
    }
}, 200);</script></div></article><div id="pagination"><div class="prev-post pull-left"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2021/06/15/%E5%86%B3%E7%AD%96%E6%A0%91%E9%9B%86%E6%88%90-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"><i class="fas fa-angle-left">&nbsp;</i><span>决策树集成-随机森林</span></a></div><div class="next-post pull-right"><span class="line line-top"></span><span class="line line-right"></span><span class="line line-bottom"></span><span class="line line-left"></span><a href="/2021/06/15/LogisticRegression%E7%AE%97%E6%B3%95/"><span>LogisticRegression算法</span><span>&nbsp;</span><i class="fas fa-angle-right"></i></a></div></div><!--div!= paginator()--></div></div><div class="button-hover" id="return-top"><i class="fas fa-arrow-up" aria-hidden="true"></i></div><footer><div id="footer"><div class="button-hover" id="side-button"><i class="fas fa-arrow-right"></i></div><div class="right-content"><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fas fa-file-o"></i></span><span id="busuanzi_value_page_pv"></span><span></span></div><div class="copyright">&copy;2017 ～ 2021 By Yyb</div></div></div></footer></div><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery-3.3.1.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/velocity.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/thirdparty/jquery.mCustomScrollbar.concat.min.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/fan.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/canvas_bg.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/utils.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/scroll.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/sidebar.js"></script><!--script(src=url)--><!--js(src=url_for(url) + '?version=' + version())--><script src="/js/copy.js"></script><!--script(src=url)--><div class="search-dialog"><div id="algolia-search-title">Algolia</div><div class="search-close-button"><i class="fa fa-times"></i></div><!--div#current-refined-values--><!--div#clear-all--><div id="search-box"></div><!--div#refinement-list--><hr><div id="hits"></div><div id="algolia-pagination"></div></div><div class="search-mask"></div><script src="/js/search/algolia.js"></script></body></html>